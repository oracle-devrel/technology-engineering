{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d36771-0326-45a4-b776-fb0bd05252a0",
   "metadata": {},
   "source": [
    "# **Valkey Search - Vector Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a85d0-9c2d-4d2b-85fd-252184d3d268",
   "metadata": {},
   "source": [
    "This notebook walks through an example of using Vector Search in OCI Cache (Redis/Valkey) running on Oracle cloud Infrastructure.\n",
    "\n",
    "- Notebook is deployed in the same private subnet as the OCI Cache cluster\n",
    "- Notebook has NAT gatway attached in the private subnet\n",
    "- Notebook has a conda env installed, with the below additional packages installed (langchain, valkey, etc)\n",
    "- Provision a OCI Cache cluster 8.1. Fetch the primary endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052d041b-90ba-40c1-b530-288bd0e57c70",
   "metadata": {},
   "source": [
    "## **Installs / Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc138f7-bc7e-483a-a51f-5a2d277d1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install langchain~=0.3 langchain_community~=0.3 langchain-aws~=0.2 valkey~=6.1 boto3~=1.40 beautifulsoup4~=4.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5423ba-c178-4a8e-a204-206b6711f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import valkey\n",
    "from valkey.commands.search.query import Query\n",
    "from valkey.commands.search.field import VectorField\n",
    "import numpy as np\n",
    "import oci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f995f295-0534-46bf-88fb-a53f47f732d8",
   "metadata": {},
   "source": [
    "## **Scrape a FAQ as example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e0bf0-fe91-4d27-a56c-26ad38bf5cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "oci_cache_faq_url = \"https://www.oracle.com/cloud/cache/faq/\"\n",
    "\n",
    "loader = WebBaseLoader(web_path=oci_cache_faq_url)\n",
    "pages = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150)\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "\n",
    "## Print example chunks\n",
    "print(chunks[2])\n",
    "print(\"---\")\n",
    "print(chunks[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc739e95-55e9-4958-a1e8-79df7f9c554d",
   "metadata": {},
   "source": [
    "## **Establish connection to OCI Cache - Valkey**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2c9fc-1d8d-470a-b94b-0badc41892f8",
   "metadata": {},
   "source": [
    "Provision an OCI Cache Cluster with Version 8.1 (currently in LA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcdaf9a-124b-4dee-ae2c-368230529cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valkey_cluster_primary_endpoint = \"Add your primary endpoint here\"\n",
    "\n",
    "valkey_client = valkey.Valkey(\n",
    "    host=valkey_cluster_primary_endpoint,\n",
    "    port=6379,\n",
    "    ssl=True,\n",
    "    ssl_cert_reqs=\"none\",\n",
    ")\n",
    "\n",
    "# The ping should return \"True\"\n",
    "valkey_client.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45026420-00e9-4762-b0a6-3c602786f555",
   "metadata": {},
   "source": [
    "## **Test GenAI Embedding model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f674054a-a575-41a4-9e96-6231d523cdd0",
   "metadata": {},
   "source": [
    "The below code only test the connection from this notebook to the GenAI Embedding model hosted on Oracle Cloud. Auth is based on the config file, which you can extract from your OCI Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a7c447-3688-4a2b-96a1-207df4816a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set two parameters:\n",
    "endpoint = \"https://inference.generativeai.eu-frankfurt-1.oci.oraclecloud.com\"\n",
    "compartment_ocid = \"add your compartment OCID here\"\n",
    "\n",
    "\n",
    "#auth\n",
    "config = oci.config.from_file('~/config', \"DEFAULT\")\n",
    "\n",
    "endpoint = \"https://inference.generativeai.eu-frankfurt-1.oci.oraclecloud.com\"\n",
    "generative_ai_inference_client = oci.generative_ai_inference.GenerativeAiInferenceClient(config=config, service_endpoint=endpoint, retry_strategy=oci.retry.NoneRetryStrategy(), timeout=(10,240))\n",
    "inputs = [\"some text\"]\n",
    "embed_text_detail = oci.generative_ai_inference.models.EmbedTextDetails()\n",
    "embed_text_detail.serving_mode = oci.generative_ai_inference.models.OnDemandServingMode(model_id=\"cohere.embed-english-v3.0\")\n",
    "embed_text_detail.inputs = inputs\n",
    "embed_text_detail.truncate = \"NONE\"\n",
    "embed_text_detail.compartment_id = compartment_ocid\n",
    "embed_text_response = generative_ai_inference_client.embed_text(embed_text_detail)\n",
    "print(\"**************************Embed Texts Result**************************\")\n",
    "print(embed_text_response.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76a55fa-faa6-486c-8bca-4c7ad11a416b",
   "metadata": {},
   "source": [
    "## **Iterate over text in chuncks, create embeddings and load to Valkey**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f12d05-c611-40c7-8892-3e706e30c711",
   "metadata": {},
   "source": [
    "The below code will embed the GenAI embedding as small function (with text/chunks as input and the embeddings as output). Then, the code will interate over the chunks, create the embeddings, and use the Valkey clien to add the embeddings to the Valkey cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd95719-01a3-4292-adf1-6b6dd425af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(inputs):\n",
    "\n",
    "    #set two variables:\n",
    "    endpoint = \"https://inference.generativeai.eu-frankfurt-1.oci.oraclecloud.com\"\n",
    "    compartment_ocid = \"add your compartement ocid here\"\n",
    "    \n",
    "    config = oci.config.from_file('~/config', \"DEFAULT\")\n",
    "    endpoint = endpoint\n",
    "    generative_ai_inference_client = oci.generative_ai_inference.GenerativeAiInferenceClient(config=config, service_endpoint=endpoint, retry_strategy=oci.retry.NoneRetryStrategy(), timeout=(10,240))\n",
    "    embed_text_detail = oci.generative_ai_inference.models.EmbedTextDetails()\n",
    "    embed_text_detail.serving_mode = oci.generative_ai_inference.models.OnDemandServingMode(model_id=\"cohere.embed-english-v3.0\")\n",
    "    embed_text_detail.inputs = inputs\n",
    "    embed_text_detail.truncate = \"NONE\"\n",
    "    embed_text_detail.compartment_id = compartment_ocid\n",
    "    embed_text_response = generative_ai_inference_client.embed_text(embed_text_detail)\n",
    "    \n",
    "    return embed_text_response.data.embeddings\n",
    "\n",
    "#embeddings to bytes function\n",
    "to_bytes = lambda x: np.array(x, dtype=np.float32).tobytes()\n",
    "\n",
    "# interate over the chunks, create the embeddings, and \"hset\" to Valkey cluster\n",
    "for i, chunk in enumerate(chunks):\n",
    "    content = chunk.page_content\n",
    "    vector_embedding = to_bytes(create_embeddings([content]))\n",
    "    valkey_client.hset(f'chunkId:{i}', mapping={'embed': vector_embedding, 'text': content})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538add3e-cabd-49e9-bc5c-1917036a71ca",
   "metadata": {},
   "source": [
    "## **Create a vector index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befaad24-672a-4503-aee1-df0e776862e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valkey_client.ft(index_name=\"embedding_index_v1\").create_index([\n",
    "    VectorField(\n",
    "        \"embed\",\n",
    "        \"HNSW\",\n",
    "        {\n",
    "            \"TYPE\": \"FLOAT32\",\n",
    "            \"DIM\": 1024,\n",
    "            \"DISTANCE_METRIC\": \"COSINE\",\n",
    "        })\n",
    "    ])\n",
    "\n",
    "#This should return \"OK\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ad9cbf-621f-420b-83d0-a4d1082b1aa7",
   "metadata": {},
   "source": [
    "## **Run an example query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a340b-9a58-41b6-806f-e5f684032d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_valkey(question):\n",
    "\n",
    "    #question to embedding to byte\n",
    "    query_vec = to_bytes(create_embeddings([question]))\n",
    "\n",
    "    # the query for Valkey. Only returns 1 text. Change to 2 or higher.\n",
    "    query = (\n",
    "        Query(\"*=>[KNN 1 @embed $vec as score]\")\n",
    "         .return_fields(\"id\", \"score\")\n",
    "         .dialect(2)\n",
    "    )\n",
    "    \n",
    "    # Find K similar document chunks\n",
    "    query_params = {\"vec\": query_vec}\n",
    "\n",
    "    #search valkey cluster\n",
    "    results = valkey_client.ft(index_name=\"embedding_index_v1\").search(query, query_params).docs\n",
    "\n",
    "    for idx, item in enumerate(results):\n",
    "        results_in_text = (valkey_client.hget(item.id, 'text'))\n",
    "    \n",
    "    return results_in_text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4459d346-0523-4110-8785-3d266a83564e",
   "metadata": {},
   "source": [
    "## **Return top 1 result as example using Vector Search in OCI Cache (Valkey 8.1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0e9d2c-1a25-4331-b581-d888cc0b550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = \"What version does OCI Cache support?\"\n",
    "question2 = \"Why would you use OCI Cache?\"\n",
    "\n",
    "results_in_text = query_valkey(question1)\n",
    "results_in_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee567dc9-9458-4da6-8f2e-1248ba439b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p311_cpu_x86_64_v1]",
   "language": "python",
   "name": "conda-env-generalml_p311_cpu_x86_64_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
