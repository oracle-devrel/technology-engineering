{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@notebook{pyspark-data_flow-application.ipynb,\n",
    "    title: PySpark,\n",
    "    summary: Develop local PySpark applications and work with remote clusters using Data Flow.,\n",
    "    developed_on: pyspark24_p37_cpu_v3,\n",
    "    keywords: pyspark, data flow, \n",
    "    license: Universal Permissive License v 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade Oracle ADS to pick up latest features and maintain compatibility with Oracle Cloud Infrastructure.\n",
    "\n",
    "!pip install -U oracle-ads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle Data Science service sample notebook.\n",
    "\n",
    "Copyright (c) 2019, 2022 Oracle, Inc. All rights reserved. Licensed under the [Universal Permissive License v 1.0](https://oss.oracle.com/licenses/upl).\n",
    "\n",
    "---\n",
    "\n",
    "# <font color=\"red\">PySpark</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=\"teal\">Oracle Cloud Infrastructure Data Science Service.</font></p>\n",
    "\n",
    "---\n",
    "\n",
    "# Overview:\n",
    "\n",
    "This notebook provides Apache Spark operations for customers by bridging the existing local PySpark workflows with cloud based capabilities. Data scientists can use their familiar local environments with JupyterLab and work with remote data and remote clusters simply by selecting a kernel. The operations that will be demonstrated are: how to use the interactive Spark environment and produce a Spark script; how to prepare and create an application; how to prepare and create a run; how to list existing dataflow applications; and how to retrieve and display the logs.\n",
    "\n",
    "The interactive Spark kernel provides a simple and efficient way to edit and build your Spark script, and easy access to read from OCI Object Storage.\n",
    "\n",
    "Compatible conda pack: [PySpark 3.2 and Data Flow](https://docs.oracle.com/iaas/data-science/using/conda-pyspark-fam.htm) for CPU on Python 3.8 (version 2.0)\n",
    "\n",
    "---\n",
    "\n",
    "## Contents:\n",
    "\n",
    "- <a href='#kernel'>Build a PySpark Script Using an Interactive Spark Kernel</a>\n",
    "- <a href=\"#ref\">References</a>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Datasets are provided as a convenience.  Datasets are considered third-party content and are not considered materials \n",
    "under your agreement with Oracle.\n",
    "    \n",
    "You can access the `orcl_attrition` dataset license [here](https://oss.oracle.com/licenses/upl).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kernel'></a>\n",
    "# Build a PySpark Script Using an Interactive Spark Kernel \n",
    "\n",
    "Set up Spark session in your PySpark conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/04 12:59:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/01/04 12:59:01 WARN ObjectStorageClient: Warning for OCI SDK usage with the Apache Connector (the OCI SDK uses the Apache Connector by default, for HTTP calls): the following operations of ObjectStorageClient return a stream : [getObject]. If using Apache Connector, make sure to close all stream instances returned by the operation(s) mentioned, explicitly, by calling 'close' to release the connection back to the connection pool and avoid any indefinite hangs, or read the stream completely. The stream instances are wrapped in an auto closeable stream, to disable this setting or for guidance on disabling this warning, possible performance optimizations, or disabling use of the Apache Connector in the OCI SDK, please see https://github.com/oracle/oci-java-sdk/blob/master/ApacheConnector-README.md\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# create a Spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Python Spark SQL basic example\")\n",
    "    .config(\"spark.driver.cores\", \"1\")\n",
    "    .config(\"spark.executor.cores\", \"1\")\n",
    "    .config(\"spark.jars\", \"oci://dataflow_app@frqap2zhtzbe/postgresql-42.7.1.jar\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = (spark.read.format(\"jdbc\").option(\"url\", \"jdbc:postgresql://129.153.75.145:5432/db\")\n",
    "    .option(\"dbtable\", \"public.samp_revenue_f\")\n",
    "    .option(\"user\", \"username\")\n",
    "    .option(\"password\", \"password\")\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\n",
    "    .option(\"ssl\", True)\n",
    "    .option(\"sslmode\", \"require\" )\n",
    "    .load()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read.format(\"jdbc\")\n",
    "    .option(\"url\", \"jdbc:postgresql://129.153.65.145:5432/db\")\n",
    "    .option(\"dbtable\", \"public.samp_revenue_f\")\n",
    "    .option(\"user\", \"username\")\n",
    "    .option(\"password\", \"password\")\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\n",
    "    .option(\"ssl\", True)\n",
    "    .option(\"sslmode\", \"require\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- shipto_addr_key: decimal(38,10) (nullable = true)\n",
      " |-- office_key: decimal(38,10) (nullable = true)\n",
      " |-- empl_key: decimal(38,10) (nullable = true)\n",
      " |-- prod_key: decimal(38,10) (nullable = true)\n",
      " |-- order_key: decimal(38,10) (nullable = true)\n",
      " |-- units: decimal(38,10) (nullable = true)\n",
      " |-- discnt_value: decimal(38,10) (nullable = true)\n",
      " |-- bill_mth_key: decimal(38,10) (nullable = true)\n",
      " |-- bill_qtr_key: decimal(38,10) (nullable = true)\n",
      " |-- bill_day_dt: timestamp (nullable = true)\n",
      " |-- order_day_dt: timestamp (nullable = true)\n",
      " |-- paid_day_dt: timestamp (nullable = true)\n",
      " |-- discnt_rate: decimal(38,10) (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- order_type: string (nullable = true)\n",
      " |-- cust_key: decimal(38,10) (nullable = true)\n",
      " |-- ship_day_dt: timestamp (nullable = true)\n",
      " |-- cost_fixed: decimal(38,10) (nullable = true)\n",
      " |-- cost_variable: decimal(38,10) (nullable = true)\n",
      " |-- src_order_number: string (nullable = true)\n",
      " |-- order_number: decimal(38,10) (nullable = true)\n",
      " |-- revenue: decimal(38,10) (nullable = true)\n",
      " |-- order_dtime1_db_tz: string (nullable = true)\n",
      " |-- order_dtime2_timezone: string (nullable = true)\n",
      " |-- order_dtime2_custom_tz: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datascience/conda/pyspark32_p38_cpu_v3/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:194: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n",
      "/home/datascience/conda/pyspark32_p38_cpu_v3/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:194: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n",
      "/home/datascience/conda/pyspark32_p38_cpu_v3/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:194: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n",
      "/home/datascience/conda/pyspark32_p38_cpu_v3/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:194: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shipto_addr_key</th>\n",
       "      <th>office_key</th>\n",
       "      <th>empl_key</th>\n",
       "      <th>prod_key</th>\n",
       "      <th>order_key</th>\n",
       "      <th>units</th>\n",
       "      <th>discnt_value</th>\n",
       "      <th>bill_mth_key</th>\n",
       "      <th>bill_qtr_key</th>\n",
       "      <th>bill_day_dt</th>\n",
       "      <th>...</th>\n",
       "      <th>cust_key</th>\n",
       "      <th>ship_day_dt</th>\n",
       "      <th>cost_fixed</th>\n",
       "      <th>cost_variable</th>\n",
       "      <th>src_order_number</th>\n",
       "      <th>order_number</th>\n",
       "      <th>revenue</th>\n",
       "      <th>order_dtime1_db_tz</th>\n",
       "      <th>order_dtime2_timezone</th>\n",
       "      <th>order_dtime2_custom_tz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1255.0000000000</td>\n",
       "      <td>6.0000000000</td>\n",
       "      <td>9.0000000000</td>\n",
       "      <td>16.0000000000</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>109.0000000000</td>\n",
       "      <td>72.0000000000</td>\n",
       "      <td>201301.0000000000</td>\n",
       "      <td>201301.0000000000</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>...</td>\n",
       "      <td>415.0000000000</td>\n",
       "      <td>2012-12-25</td>\n",
       "      <td>237.2600000000</td>\n",
       "      <td>334.5200000000</td>\n",
       "      <td>None</td>\n",
       "      <td>1053.0000000000</td>\n",
       "      <td>1120.9300000000</td>\n",
       "      <td>21-DEC-12 12.47.43.000000000 PM</td>\n",
       "      <td>CET</td>\n",
       "      <td>21-DEC-12 07.47.43.000000000 PM -05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1341.0000000000</td>\n",
       "      <td>19.0000000000</td>\n",
       "      <td>6.0000000000</td>\n",
       "      <td>4.0000000000</td>\n",
       "      <td>2.0000000000</td>\n",
       "      <td>29.0000000000</td>\n",
       "      <td>0E-10</td>\n",
       "      <td>201301.0000000000</td>\n",
       "      <td>201301.0000000000</td>\n",
       "      <td>2013-01-14</td>\n",
       "      <td>...</td>\n",
       "      <td>933.0000000000</td>\n",
       "      <td>2012-12-26</td>\n",
       "      <td>158.1700000000</td>\n",
       "      <td>165.4400000000</td>\n",
       "      <td>None</td>\n",
       "      <td>2433.0000000000</td>\n",
       "      <td>486.6600000000</td>\n",
       "      <td>22-DEC-12 02.10.55.000000000 AM</td>\n",
       "      <td>Europe/Rome</td>\n",
       "      <td>22-DEC-12 09.10.55.000000000 AM -05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2032.0000000000</td>\n",
       "      <td>20.0000000000</td>\n",
       "      <td>14.0000000000</td>\n",
       "      <td>20.0000000000</td>\n",
       "      <td>3.0000000000</td>\n",
       "      <td>51.0000000000</td>\n",
       "      <td>86.0000000000</td>\n",
       "      <td>201301.0000000000</td>\n",
       "      <td>201301.0000000000</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>...</td>\n",
       "      <td>231.0000000000</td>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>337.2400000000</td>\n",
       "      <td>643.2200000000</td>\n",
       "      <td>None</td>\n",
       "      <td>1896.0000000000</td>\n",
       "      <td>319.8100000000</td>\n",
       "      <td>18-DEC-12 06.03.49.000000000 AM</td>\n",
       "      <td>CET</td>\n",
       "      <td>18-DEC-12 01.03.49.000000000 PM -05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2070.0000000000</td>\n",
       "      <td>10.0000000000</td>\n",
       "      <td>24.0000000000</td>\n",
       "      <td>16.0000000000</td>\n",
       "      <td>4.0000000000</td>\n",
       "      <td>11.0000000000</td>\n",
       "      <td>60.0000000000</td>\n",
       "      <td>201301.0000000000</td>\n",
       "      <td>201301.0000000000</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>...</td>\n",
       "      <td>134.0000000000</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>207.4200000000</td>\n",
       "      <td>298.2000000000</td>\n",
       "      <td>None</td>\n",
       "      <td>6259.0000000000</td>\n",
       "      <td>104.7300000000</td>\n",
       "      <td>15-DEC-12 10.04.36.000000000 AM</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>15-DEC-12 04.04.36.000000000 PM -05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1409.0000000000</td>\n",
       "      <td>17.0000000000</td>\n",
       "      <td>16.0000000000</td>\n",
       "      <td>18.0000000000</td>\n",
       "      <td>5.0000000000</td>\n",
       "      <td>5.0000000000</td>\n",
       "      <td>186.0000000000</td>\n",
       "      <td>201301.0000000000</td>\n",
       "      <td>201301.0000000000</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0000000000</td>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>656.5700000000</td>\n",
       "      <td>500.7700000000</td>\n",
       "      <td>None</td>\n",
       "      <td>18462.0000000000</td>\n",
       "      <td>99.5100000000</td>\n",
       "      <td>15-DEC-12 03.55.24.000000000 PM</td>\n",
       "      <td>Europe/Paris</td>\n",
       "      <td>15-DEC-12 10.55.24.000000000 PM -05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70995</th>\n",
       "      <td>2436.0000000000</td>\n",
       "      <td>6.0000000000</td>\n",
       "      <td>16.0000000000</td>\n",
       "      <td>18.0000000000</td>\n",
       "      <td>70996.0000000000</td>\n",
       "      <td>19.0000000000</td>\n",
       "      <td>0E-10</td>\n",
       "      <td>201306.0000000000</td>\n",
       "      <td>201302.0000000000</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>...</td>\n",
       "      <td>404.0000000000</td>\n",
       "      <td>2013-06-22</td>\n",
       "      <td>1079.6100000000</td>\n",
       "      <td>1364.3100000000</td>\n",
       "      <td>None</td>\n",
       "      <td>64031.0000000000</td>\n",
       "      <td>395.5300000000</td>\n",
       "      <td>16-JUN-13 04.17.24.000000000 PM</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>16-JUN-13 10.17.24.000000000 PM -05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70996</th>\n",
       "      <td>1352.0000000000</td>\n",
       "      <td>6.0000000000</td>\n",
       "      <td>24.0000000000</td>\n",
       "      <td>19.0000000000</td>\n",
       "      <td>70997.0000000000</td>\n",
       "      <td>72.0000000000</td>\n",
       "      <td>91.0000000000</td>\n",
       "      <td>201408.0000000000</td>\n",
       "      <td>201403.0000000000</td>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0000000000</td>\n",
       "      <td>2014-07-29</td>\n",
       "      <td>185.0300000000</td>\n",
       "      <td>231.6200000000</td>\n",
       "      <td>None</td>\n",
       "      <td>69216.0000000000</td>\n",
       "      <td>1697.4800000000</td>\n",
       "      <td>15-JUL-14 09.06.27.000000000 PM</td>\n",
       "      <td>US/Pacific</td>\n",
       "      <td>15-JUL-14 07.06.27.000000000 PM -05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70997</th>\n",
       "      <td>2163.0000000000</td>\n",
       "      <td>6.0000000000</td>\n",
       "      <td>25.0000000000</td>\n",
       "      <td>19.0000000000</td>\n",
       "      <td>70998.0000000000</td>\n",
       "      <td>25.0000000000</td>\n",
       "      <td>0E-10</td>\n",
       "      <td>201511.0000000000</td>\n",
       "      <td>201504.0000000000</td>\n",
       "      <td>2015-11-26</td>\n",
       "      <td>...</td>\n",
       "      <td>209.0000000000</td>\n",
       "      <td>2015-11-22</td>\n",
       "      <td>174.5900000000</td>\n",
       "      <td>276.4100000000</td>\n",
       "      <td>None</td>\n",
       "      <td>45366.0000000000</td>\n",
       "      <td>635.5500000000</td>\n",
       "      <td>16-NOV-15 09.51.42.000000000 PM</td>\n",
       "      <td>CET</td>\n",
       "      <td>17-NOV-15 04.51.42.000000000 AM -05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70998</th>\n",
       "      <td>1496.0000000000</td>\n",
       "      <td>6.0000000000</td>\n",
       "      <td>24.0000000000</td>\n",
       "      <td>19.0000000000</td>\n",
       "      <td>70999.0000000000</td>\n",
       "      <td>12.0000000000</td>\n",
       "      <td>86.0000000000</td>\n",
       "      <td>201506.0000000000</td>\n",
       "      <td>201502.0000000000</td>\n",
       "      <td>2015-06-27</td>\n",
       "      <td>...</td>\n",
       "      <td>375.0000000000</td>\n",
       "      <td>2015-06-19</td>\n",
       "      <td>130.5700000000</td>\n",
       "      <td>368.0100000000</td>\n",
       "      <td>None</td>\n",
       "      <td>45064.0000000000</td>\n",
       "      <td>318.5900000000</td>\n",
       "      <td>08-JUN-15 03.45.43.000000000 PM</td>\n",
       "      <td>Europe/Amsterdam</td>\n",
       "      <td>08-JUN-15 10.45.43.000000000 PM -05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70999</th>\n",
       "      <td>50.0000000000</td>\n",
       "      <td>6.0000000000</td>\n",
       "      <td>6.0000000000</td>\n",
       "      <td>8.0000000000</td>\n",
       "      <td>71000.0000000000</td>\n",
       "      <td>42.0000000000</td>\n",
       "      <td>0E-10</td>\n",
       "      <td>201306.0000000000</td>\n",
       "      <td>201302.0000000000</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>...</td>\n",
       "      <td>479.0000000000</td>\n",
       "      <td>2013-06-22</td>\n",
       "      <td>194.7300000000</td>\n",
       "      <td>606.9000000000</td>\n",
       "      <td>None</td>\n",
       "      <td>45689.0000000000</td>\n",
       "      <td>547.4800000000</td>\n",
       "      <td>11-JUN-13 06.23.04.000000000 AM</td>\n",
       "      <td>Etc/Greenwich</td>\n",
       "      <td>11-JUN-13 11.23.04.000000000 AM -05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71000 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       shipto_addr_key     office_key       empl_key       prod_key  \\\n",
       "0      1255.0000000000   6.0000000000   9.0000000000  16.0000000000   \n",
       "1      1341.0000000000  19.0000000000   6.0000000000   4.0000000000   \n",
       "2      2032.0000000000  20.0000000000  14.0000000000  20.0000000000   \n",
       "3      2070.0000000000  10.0000000000  24.0000000000  16.0000000000   \n",
       "4      1409.0000000000  17.0000000000  16.0000000000  18.0000000000   \n",
       "...                ...            ...            ...            ...   \n",
       "70995  2436.0000000000   6.0000000000  16.0000000000  18.0000000000   \n",
       "70996  1352.0000000000   6.0000000000  24.0000000000  19.0000000000   \n",
       "70997  2163.0000000000   6.0000000000  25.0000000000  19.0000000000   \n",
       "70998  1496.0000000000   6.0000000000  24.0000000000  19.0000000000   \n",
       "70999    50.0000000000   6.0000000000   6.0000000000   8.0000000000   \n",
       "\n",
       "              order_key           units    discnt_value       bill_mth_key  \\\n",
       "0          1.0000000000  109.0000000000   72.0000000000  201301.0000000000   \n",
       "1          2.0000000000   29.0000000000           0E-10  201301.0000000000   \n",
       "2          3.0000000000   51.0000000000   86.0000000000  201301.0000000000   \n",
       "3          4.0000000000   11.0000000000   60.0000000000  201301.0000000000   \n",
       "4          5.0000000000    5.0000000000  186.0000000000  201301.0000000000   \n",
       "...                 ...             ...             ...                ...   \n",
       "70995  70996.0000000000   19.0000000000           0E-10  201306.0000000000   \n",
       "70996  70997.0000000000   72.0000000000   91.0000000000  201408.0000000000   \n",
       "70997  70998.0000000000   25.0000000000           0E-10  201511.0000000000   \n",
       "70998  70999.0000000000   12.0000000000   86.0000000000  201506.0000000000   \n",
       "70999  71000.0000000000   42.0000000000           0E-10  201306.0000000000   \n",
       "\n",
       "            bill_qtr_key bill_day_dt  ...        cust_key ship_day_dt  \\\n",
       "0      201301.0000000000  2013-01-07  ...  415.0000000000  2012-12-25   \n",
       "1      201301.0000000000  2013-01-14  ...  933.0000000000  2012-12-26   \n",
       "2      201301.0000000000  2013-01-02  ...  231.0000000000  2012-12-27   \n",
       "3      201301.0000000000  2013-01-03  ...  134.0000000000  2012-12-30   \n",
       "4      201301.0000000000  2013-01-04  ...   56.0000000000  2012-12-27   \n",
       "...                  ...         ...  ...             ...         ...   \n",
       "70995  201302.0000000000  2013-06-28  ...  404.0000000000  2013-06-22   \n",
       "70996  201403.0000000000  2014-08-01  ...   37.0000000000  2014-07-29   \n",
       "70997  201504.0000000000  2015-11-26  ...  209.0000000000  2015-11-22   \n",
       "70998  201502.0000000000  2015-06-27  ...  375.0000000000  2015-06-19   \n",
       "70999  201302.0000000000  2013-06-28  ...  479.0000000000  2013-06-22   \n",
       "\n",
       "            cost_fixed    cost_variable src_order_number      order_number  \\\n",
       "0       237.2600000000   334.5200000000             None   1053.0000000000   \n",
       "1       158.1700000000   165.4400000000             None   2433.0000000000   \n",
       "2       337.2400000000   643.2200000000             None   1896.0000000000   \n",
       "3       207.4200000000   298.2000000000             None   6259.0000000000   \n",
       "4       656.5700000000   500.7700000000             None  18462.0000000000   \n",
       "...                ...              ...              ...               ...   \n",
       "70995  1079.6100000000  1364.3100000000             None  64031.0000000000   \n",
       "70996   185.0300000000   231.6200000000             None  69216.0000000000   \n",
       "70997   174.5900000000   276.4100000000             None  45366.0000000000   \n",
       "70998   130.5700000000   368.0100000000             None  45064.0000000000   \n",
       "70999   194.7300000000   606.9000000000             None  45689.0000000000   \n",
       "\n",
       "               revenue               order_dtime1_db_tz order_dtime2_timezone  \\\n",
       "0      1120.9300000000  21-DEC-12 12.47.43.000000000 PM                   CET   \n",
       "1       486.6600000000  22-DEC-12 02.10.55.000000000 AM           Europe/Rome   \n",
       "2       319.8100000000  18-DEC-12 06.03.49.000000000 AM                   CET   \n",
       "3       104.7300000000  15-DEC-12 10.04.36.000000000 AM         Europe/London   \n",
       "4        99.5100000000  15-DEC-12 03.55.24.000000000 PM          Europe/Paris   \n",
       "...                ...                              ...                   ...   \n",
       "70995   395.5300000000  16-JUN-13 04.17.24.000000000 PM         Europe/London   \n",
       "70996  1697.4800000000  15-JUL-14 09.06.27.000000000 PM            US/Pacific   \n",
       "70997   635.5500000000  16-NOV-15 09.51.42.000000000 PM                   CET   \n",
       "70998   318.5900000000  08-JUN-15 03.45.43.000000000 PM      Europe/Amsterdam   \n",
       "70999   547.4800000000  11-JUN-13 06.23.04.000000000 AM         Etc/Greenwich   \n",
       "\n",
       "                       order_dtime2_custom_tz  \n",
       "0      21-DEC-12 07.47.43.000000000 PM -05:00  \n",
       "1      22-DEC-12 09.10.55.000000000 AM -05:00  \n",
       "2      18-DEC-12 01.03.49.000000000 PM -05:00  \n",
       "3      15-DEC-12 04.04.36.000000000 PM -05:00  \n",
       "4      15-DEC-12 10.55.24.000000000 PM -05:00  \n",
       "...                                       ...  \n",
       "70995  16-JUN-13 10.17.24.000000000 PM -05:00  \n",
       "70996  15-JUL-14 07.06.27.000000000 PM -05:00  \n",
       "70997  17-NOV-15 04.51.42.000000000 AM -05:00  \n",
       "70998  08-JUN-15 10.45.43.000000000 PM -05:00  \n",
       "70999  11-JUN-13 11.23.04.000000000 AM -05:00  \n",
       "\n",
       "[71000 rows x 26 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"f_revenue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[prod_key: decimal(38,10), sum(revenue): decimal(38,10)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dn = (\n",
    "    spark.sql(\"\"\"SELECT prod_key, sum(revenue) FROM f_revenue group by prod_key\"\"\")\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "dn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize how monthly income and age relate to one another in the context of years in industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table_name = \"agg_prod_revenue\"\n",
    "\n",
    "spark.createDataFrame(dn).write.format('jdbc').options(\n",
    "    url=\"jdbc:postgresql://129.153.75.145:5432/amer\",\n",
    "    driver='org.postgresql.Driver',\n",
    "    dbtable=result_table_name,\n",
    "    user='bisample',\n",
    "    password='WelcomeBack123#',\n",
    "    ssl=True,\n",
    "    sslmode='require').mode('append').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dn.write.format(\"jdbc\")\\\n",
    "    .option(\"url\", \"jdbc:postgresql://129.153.75.145:5432/amer\")\\\n",
    "    .option(\"dbtable\", \"public.agg_prod_revenue\")\\\n",
    "    .option(\"user\", \"bisample\")\\\n",
    "    .option(\"password\", \"WelcomeBack123#\")\\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\\\n",
    "    .option(\"ssl\", True)\\\n",
    "    .option(\"sslmode\", \"require\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View all of the columns in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"show columns from emp_attrition\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a few columns using Apache Spark and convert it into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.sql(\n",
    "        \"\"\"\n",
    "         SELECT\n",
    "            Age,\n",
    "            MonthlyIncome,\n",
    "            YearsInIndustry\n",
    "          FROM\n",
    "            emp_attrition \"\"\"\n",
    "    )\n",
    "    .limit(10)\n",
    "    .toPandas()\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also work with different compression formats within Dataflow. For example snappy parquet: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to a snappy parquet file\n",
    "df.to_parquet(\"emp_attrition.parquet.snappy\", compression=\"snappy\")\n",
    "pd.read_parquet(\"emp_attrition.parquet.snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are able to read in this snappy parquet file to an Apache Spark dataframe\n",
    "read_snappy_df = (\n",
    "    SparkSession.builder.appName(\"Snappy Compression Loading Example\")\n",
    "    .config(\"spark.io.compression.codec\", \"org.apache.spark.io.SnappyCompressionCodec\")\n",
    "    .getOrCreate()\n",
    "    .read.format(\"parquet\")\n",
    "    .load(f\"{os.getcwd()}/emp_attrition.parquet.snappy\")\n",
    ")\n",
    "\n",
    "read_snappy_df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: other compression formats Data Flow supports today include snappy parquet (example above) and gzip on both csv and parquet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='df_app'></a>\n",
    "## Create a Data Flow application\n",
    "`oracle-ads` provides different ways to submit your code to Data Flow for workloads that require larger resources. To learn more, read the [user guide](https://accelerated-data-science.readthedocs.io/en/latest/user_guide/apachespark/dataflow.html#)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref\"></a>\n",
    "# References\n",
    "\n",
    "- [ADS Library Documentation](https://accelerated-data-science.readthedocs.io/en/latest/index.html)\n",
    "- [Data Science YouTube Videos](https://www.youtube.com/playlist?list=PLKCk3OyNwIzv6CWMhvqSB_8MLJIZdO80L)\n",
    "- [OCI Data Science Documentation](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm)\n",
    "- [Oracle Data & AI Blog](https://blogs.oracle.com/datascience/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark32_p38_cpu_v3]",
   "language": "python",
   "name": "conda-env-pyspark32_p38_cpu_v3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
